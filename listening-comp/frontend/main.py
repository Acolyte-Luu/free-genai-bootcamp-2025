# Initialize PyTorch first to avoid Streamlit file watcher issues
import torch
# Force initialization 
_ = torch.zeros(1)

import streamlit as st
from typing import Dict
import json
from collections import Counter
import re

import sys
import os
# Add parent directory to path BEFORE importing backend modules
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

# Now import backend modules AFTER path setup
import backend.rag
import backend.interactive

from backend.chat import LocalLLMChat
from backend.get_transcript import YouTubeTranscriptDownloader


# Page config
st.set_page_config(
    page_title="Japanese Learning Assistant",
    page_icon="üéå",
    layout="wide"
)

# Initialize session state
if 'transcript' not in st.session_state:
    st.session_state.transcript = None
if 'messages' not in st.session_state:
    st.session_state.messages = []

def render_header():
    """Render the header section"""
    st.title("üéå Japanese Learning Assistant")
    st.markdown("""
    Transform YouTube transcripts into interactive Japanese learning experiences.
    
    This tool demonstrates:
    - Base LLM Capabilities
    - RAG (Retrieval Augmented Generation)
    - Amazon Bedrock Integration
    - Agent-based Learning Systems
    """)

def render_sidebar():
    """Render the sidebar with component selection"""
    with st.sidebar:
        st.header("Development Stages")
        
        # Main component selection
        selected_stage = st.radio(
            "Select Stage:",
            [
                "1. Chat with LocalLLM",
                "2. Raw Transcript",
                "3. Structured Data",
                "4. RAG Implementation",
                "5. Interactive Learning"
            ]
        )
        
        # Stage descriptions
        stage_info = {
            "1. Chat with LocalLLM": """
            **Current Focus:**
            - Basic Japanese learning
            - Understanding LLM capabilities
            - Identifying limitations
            """,
            
            "2. Raw Transcript": """
            **Current Focus:**
            - YouTube transcript download
            - Raw text visualization
            - Initial data examination
            """,
            
            "3. Structured Data": """
            **Current Focus:**
            - Text cleaning
            - Dialogue extraction
            - Data structuring
            """,
            
            "4. RAG Implementation": """
            **Current Focus:**
            - Bedrock embeddings
            - Vector storage
            - Context retrieval
            """,
            
            "5. Interactive Learning": """
            **Current Focus:**
            - Scenario generation
            - Audio synthesis
            - Interactive practice
            """
        }
        
        st.markdown("---")
        st.markdown(stage_info[selected_stage])
        
        return selected_stage

def render_chat_stage():
    """Render an improved chat interface"""
    st.header("Chat with LocalLLM")

    # Initialize BedrockChat instance if not in session state
    if 'local_llm_chat' not in st.session_state:
        st.session_state.local_llm_chat = LocalLLMChat()

    # Introduction text
    st.markdown("""
    Start by exploring Nova's base Japanese language capabilities. Try asking questions about Japanese grammar, 
    vocabulary, or cultural aspects.
    """)

    # Initialize chat history if not exists
    if "messages" not in st.session_state:
        st.session_state.messages = []

    # Display chat messages
    for message in st.session_state.messages:
        with st.chat_message(message["role"], avatar="üßë‚Äçüíª" if message["role"] == "user" else "ü§ñ"):
            st.markdown(message["content"])

    # Chat input area
    if prompt := st.chat_input("Ask about Japanese language..."):
        # Process the user input
        process_message(prompt)

    # Example questions in sidebar
    with st.sidebar:
        st.markdown("### Try These Examples")
        example_questions = [
            "How do I say 'Where is the train station?' in Japanese?",
            "Explain the difference between „ÅØ and „Åå",
            "What's the polite form of È£ü„Åπ„Çã?",
            "How do I count objects in Japanese?",
            "What's the difference between „Åì„Çì„Å´„Å°„ÅØ and „Åì„Çì„Å∞„Çì„ÅØ?",
            "How do I ask for directions politely?"
        ]
        
        for q in example_questions:
            if st.button(q, use_container_width=True, type="secondary"):
                # Process the example question
                process_message(q)
                st.rerun()

    # Add a clear chat button
    if st.session_state.messages:
        if st.button("Clear Chat", type="primary"):
            st.session_state.messages = []
            st.rerun()

def process_message(message: str):
    """Process a message and generate a response"""
    # Add user message to state and display
    st.session_state.messages.append({"role": "user", "content": message})
    with st.chat_message("user", avatar="üßë‚Äçüíª"):
        st.markdown(message)

    # Generate and display assistant's response
    with st.chat_message("assistant", avatar="ü§ñ"):
        response = st.session_state.local_llm_chat.generate_response(message)
        if response:
            st.markdown(response)
            st.session_state.messages.append({"role": "assistant", "content": response})



def count_characters(text):
    """Count Japanese and total characters in text"""
    if not text:
        return 0, 0
        
    def is_japanese(char):
        return any([
            '\u4e00' <= char <= '\u9fff',  # Kanji
            '\u3040' <= char <= '\u309f',  # Hiragana
            '\u30a0' <= char <= '\u30ff',  # Katakana
        ])
    
    jp_chars = sum(1 for char in text if is_japanese(char))
    return jp_chars, len(text)

def render_transcript_stage():
    """Render the raw transcript stage"""
    st.header("Raw Transcript Processing")
    
    # URL input
    url = st.text_input(
        "YouTube URL",
        placeholder="Enter a Japanese lesson YouTube URL"
    )
    
    # Download button and processing
    if url:
        if st.button("Download Transcript"):
            try:
                downloader = YouTubeTranscriptDownloader()
                transcript = downloader.get_transcript(url)
                if transcript:
                    # Store the raw transcript text in session state
                    transcript_text = "\n".join([entry['text'] for entry in transcript])
                    st.session_state.transcript = transcript_text
                    st.success("Transcript downloaded successfully!")
                else:
                    st.error("No transcript found for this video.")
            except Exception as e:
                st.error(f"Error downloading transcript: {str(e)}")

    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("Raw Transcript")
        if st.session_state.transcript:
            st.text_area(
                label="Raw text",
                value=st.session_state.transcript,
                height=400,
                disabled=True
            )
    
        else:
            st.info("No transcript loaded yet")
    
    with col2:
        st.subheader("Transcript Stats")
        if st.session_state.transcript:
            # Calculate stats
            jp_chars, total_chars = count_characters(st.session_state.transcript)
            total_lines = len(st.session_state.transcript.split('\n'))
            
            # Display stats
            st.metric("Total Characters", total_chars)
            st.metric("Japanese Characters", jp_chars)
            st.metric("Total Lines", total_lines)
        else:
            st.info("Load a transcript to see statistics")

def render_structured_stage():
    """Render the structured data stage"""
    st.header("Structured Data Processing")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("Dialogue Extraction")
        # Placeholder for dialogue processing
        st.info("Dialogue extraction will be implemented here")
        
    with col2:
        st.subheader("Data Structure")
        # Placeholder for structured data view
        st.info("Structured data view will be implemented here")

def render_rag_stage():
    """Render the RAG implementation stage"""
    st.header("RAG System")
    
    # Query input
    query = st.text_input(
        "Test Query",
        placeholder="Enter a question about Japanese..."
    )
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("Retrieved Context")
        # Placeholder for retrieved contexts
        st.info("Retrieved contexts will appear here")
        
    with col2:
        st.subheader("Generated Response")
        # Placeholder for LLM response
        st.info("Generated response will appear here")

def render_interactive_stage():
    """Render the interactive learning stage with RAG"""
    st.header("Interactive Learning")
    
    # Initialize practice generator if not exists
    if 'practice_generator' not in st.session_state:
        from backend.interactive import InteractivePracticeGenerator
        st.session_state.practice_generator = InteractivePracticeGenerator()
    
    if 'current_question' not in st.session_state:
        st.session_state.current_question = None
    
    # Practice type selection
    practice_type = st.selectbox(
        "Select Practice Type",
        ["Dialogue Practice", "Vocabulary Quiz", "Listening Exercise"]
    )
    
    # Generate button
    if st.button("Generate New Practice Question"):
        with st.spinner("Generating question..."):
            try:
                question_data = st.session_state.practice_generator.generate_question(practice_type)
                st.session_state.current_question = question_data
            except Exception as e:
                st.error(f"Error generating question: {str(e)}")
    
    # Display question if available
    if st.session_state.current_question:
        col1, col2 = st.columns([2, 1])
        
        with col1:
            st.subheader("Practice Scenario")
            
            # Display setup/situation/action based on practice type
            if practice_type == "Dialogue Practice":
                st.markdown(f"**Setup:** {st.session_state.current_question['setup']}")
            elif practice_type == "Vocabulary Quiz":
                st.markdown(f"**Situation:** {st.session_state.current_question['setup']}")
            else:
                st.markdown(f"**Action:** {st.session_state.current_question['setup']}")
                
            st.markdown(f"**Question:** {st.session_state.current_question['question']}")
            
            # Display options
            options = st.session_state.current_question['options']
            selected = st.radio("Choose your answer:", 
                               [f"{i+1}. {option}" for i, option in enumerate(options)])
            
            # Get selected index (0-based)
            selected_index = int(selected.split('.')[0]) - 1
            
            # Check answer button
            if st.button("Check Answer"):
                correct_index = st.session_state.current_question["correct_index"]
                if selected_index == correct_index:
                    st.success("Correct! Great job!")
                else:
                    st.error(f"Not quite. The correct answer is: {correct_index + 1}. {options[correct_index]}")
        
        with col2:
            st.subheader("Similar Questions")
            
            # Show the retrieved similar questions
            if 'similar_questions' in st.session_state.current_question:
                for i, q in enumerate(st.session_state.current_question['similar_questions']):
                    with st.expander(f"Example {i+1}"):
                        st.markdown(q["question"])
                        
            st.subheader("Audio")
            st.info("Audio feature coming soon!")
    else:
        st.info("Click 'Generate New Practice Question' to start")

def main():
    render_header()
    selected_stage = render_sidebar()
    
    # Render appropriate stage
    if selected_stage == "1. Chat with LocalLLM":
        render_chat_stage()
    elif selected_stage == "2. Raw Transcript":
        render_transcript_stage()
    elif selected_stage == "3. Structured Data":
        render_structured_stage()
    elif selected_stage == "4. RAG Implementation":
        render_rag_stage()
    elif selected_stage == "5. Interactive Learning":
        render_interactive_stage()
    
    # Debug section at the bottom
    with st.expander("Debug Information"):
        st.json({
            "selected_stage": selected_stage,
            "transcript_loaded": st.session_state.transcript is not None,
            "chat_messages": len(st.session_state.messages)
        })

if __name__ == "__main__":
    main()